---
title: Random Forests for Big Data
authors:
- Robin Genuer
- Jean Michel Poggi
- Christine Tuleau-Malot
- Nathalie Villa-Vialaneix
date: '2017-09-01'
publishDate: '2024-06-05T21:10:27.945818Z'
publication_types:
- article-journal
publication: '*Big Data Research*'
doi: 10.1016/J.BDR.2017.07.003
abstract: Big Data is one of the major challenges of statistical science and has numerous
  consequences from algorithmic and theoretical viewpoints. Big Data always involve
  massive data but they also often include online data and data heterogeneity. Recently
  some statistical methods have been adapted to process Big Data, like linear regression
  models, clustering methods and bootstrapping schemes. Based on decision trees combined
  with aggregation and bootstrap ideas, random forests were introduced by Breiman
  in 2001. They are a powerful nonparametric statistical method allowing to consider
  in a single and versatile framework regression problems, as well as two-class and
  multi-class classification problems. Focusing on classification problems, this paper
  proposes a selective review of available proposals that deal with scaling random
  forests to Big Data problems. These proposals rely on parallel environments or on
  online adaptations of random forests. We also describe how out-of-bag error is addressed
  in these methods. Then, we formulate various remarks for random forests in the Big
  Data context. Finally, we experiment five variants on two massive datasets (15 and
  120 millions of observations), a simulated one as well as real world data. One variant
  relies on subsampling while three others are related to parallel implementations
  of random forests and involve either various adaptations of bootstrap to Big Data
  or “divide-and-conquer” approaches. The fifth variant is related to online learning
  of random forests. These numerical experiments lead to highlight the relative performance
  of the different variants, as well as some of their limitations.
tags:
- Bag of little bootstraps
- Big Data
- On-line learning
- Parallel computing
- R
- Random forest
---
