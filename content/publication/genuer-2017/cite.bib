@article{Genuer2017,
 abstract = {Big Data is one of the major challenges of statistical science and has numerous consequences from algorithmic and theoretical viewpoints. Big Data always involve massive data but they also often include online data and data heterogeneity. Recently some statistical methods have been adapted to process Big Data, like linear regression models, clustering methods and bootstrapping schemes. Based on decision trees combined with aggregation and bootstrap ideas, random forests were introduced by Breiman in 2001. They are a powerful nonparametric statistical method allowing to consider in a single and versatile framework regression problems, as well as two-class and multi-class classification problems. Focusing on classification problems, this paper proposes a selective review of available proposals that deal with scaling random forests to Big Data problems. These proposals rely on parallel environments or on online adaptations of random forests. We also describe how out-of-bag error is addressed in these methods. Then, we formulate various remarks for random forests in the Big Data context. Finally, we experiment five variants on two massive datasets (15 and 120 millions of observations), a simulated one as well as real world data. One variant relies on subsampling while three others are related to parallel implementations of random forests and involve either various adaptations of bootstrap to Big Data or “divide-and-conquer” approaches. The fifth variant is related to online learning of random forests. These numerical experiments lead to highlight the relative performance of the different variants, as well as some of their limitations.},
 author = {Robin Genuer and Jean Michel Poggi and Christine Tuleau-Malot and Nathalie Villa-Vialaneix},
 doi = {10.1016/J.BDR.2017.07.003},
 issn = {2214-5796},
 journal = {Big Data Research},
 keywords = {Bag of little bootstraps,Big Data,On-line learning,Parallel computing,R,Random forest},
 month = {9},
 pages = {28-46},
 publisher = {Elsevier},
 title = {Random Forests for Big Data},
 volume = {9},
 year = {2017}
}
